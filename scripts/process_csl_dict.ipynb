{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for preprocess of corpus in CSL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dictionary.txt',encoding='utf-8')\n",
    "words = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build isl dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "isl_dictionary = {}\n",
    "for word in words:\n",
    "    data = word.rstrip('\\n').split()\n",
    "    index = int(data[0])\n",
    "    token = data[1]\n",
    "    isl_dictionary[token] = index\n",
    "def reverse_dictionary(dictionary):\n",
    "    reverse_dict = {}\n",
    "    for k,v in dictionary.items():\n",
    "        reverse_dict[v] = k\n",
    "    return reverse_dict\n",
    "isl_dictionary\n",
    "for k in range(500):\n",
    "    if not k in isl_dictionary.values():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build csl dictionary and reverse dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_cut(word):\n",
    "    if word == '女朋友':\n",
    "        return ['女','朋友']\n",
    "    elif word == '现实情况':\n",
    "        return ['现实','情况']\n",
    "    elif word == '自由恋爱':\n",
    "        return ['自由','恋爱']\n",
    "    elif word == '扭转局面':\n",
    "        return ['扭转','局面']\n",
    "    elif word == '事业成功':\n",
    "        return ['事业','成功']\n",
    "    elif word == '经验丰富':\n",
    "        return ['经验','丰富']\n",
    "    elif word == '有雨':\n",
    "        return ['有','雨']\n",
    "    elif word == '他人':\n",
    "        return ['别人']\n",
    "    elif word == '圆满成功':\n",
    "        return ['圆满','成功']\n",
    "    elif word == '针线':\n",
    "        return ['针','线']\n",
    "    elif word == '星星':\n",
    "        return ['星']\n",
    "    elif word == '小孩子':\n",
    "        return ['小孩儿（儿童、少年）']\n",
    "    else:\n",
    "        return [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build CSL dictionary successfully!\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "def build_csl_dictionary():\n",
    "    annotation_file = open(\"corpus.txt\",'r')\n",
    "    corpus = annotation_file.readlines()\n",
    "    corpus = [sentence.rstrip('\\n').split()[1] for sentence in corpus]\n",
    "    # Create a dictionary which maps tokens to indices (train contains all the training sentences)\n",
    "    freq_list = Counter()\n",
    "    punctuation = ['\\ufeff']\n",
    "    for sentence in corpus:\n",
    "        tmp_sentence = []\n",
    "        for word in jieba.cut(sentence):\n",
    "            if not word in punctuation:\n",
    "                word = manual_cut(word)\n",
    "                tmp_sentence.extend(word)\n",
    "        freq_list.update(tmp_sentence)\n",
    "\n",
    "    # 按照词的出现频率建立词典，词频越高索引越靠前\n",
    "    freq_list = sorted(freq_list.items(),key=lambda item:item[1],reverse=True)\n",
    "    dictionary = {}\n",
    "    dictionary['<pad>'] = 0\n",
    "    dictionary['<bos>'] = 1\n",
    "    dictionary['<eos>'] = 2\n",
    "    for i,item in enumerate(freq_list):\n",
    "        dictionary[item[0]] = i+3\n",
    "    print(\"Build CSL dictionary successfully!\")\n",
    "    return dictionary\n",
    "csl_dictionary = build_csl_dictionary()\n",
    "reverse_dict = reverse_dictionary(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update isl_dictionary to handle the words with same meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他   他（她、它）\n",
      "外祖父   外祖父（外公）\n",
      "祖父   祖父（爷爷）\n",
      "基础   基础（根据）\n",
      "成功   成效（成功）\n",
      "她   他（她、它）\n",
      "儿子   儿子（男孩）\n",
      "改善   改善（改良）\n",
      "好   好转\n",
      "女   女儿（女孩）\n",
      "医生   医生（大夫）\n",
      "外祖母   外祖母（外婆）\n",
      "祖母   祖母（奶奶）\n",
      "歪   歪（倾向）\n",
      "颜色   颜色（彩色）\n",
      "锋利   尖（锋利、尖锐）\n",
      "放弃   放弃（放）\n",
      "牙刷   牙刷（刷牙）\n",
      "没有   没有（无）\n",
      "去   去（出）\n",
      "平等   平（平等）\n"
     ]
    }
   ],
   "source": [
    "def isIndict(k):\n",
    "    global isl_dictionary\n",
    "    for word in isl_dictionary.keys():\n",
    "        if k == word:\n",
    "            return word\n",
    "        elif k in word and k!='的' and k!='有':\n",
    "            print(k,' ',word)\n",
    "            isl_dictionary[k] = isl_dictionary[word]\n",
    "            return word\n",
    "    return -1\n",
    "isl_in_csl_dictionary = {}\n",
    "for k in csl_dictionary.keys():\n",
    "    word = isIndict(k)\n",
    "    if word!=-1:\n",
    "        index = isl_dictionary[word]\n",
    "        isl_in_csl_dictionary[k] = index\n",
    "# isl_in_csl_dictionary = sorted(isl_in_csl_dictionary.items(),key=lambda item:item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate subset file for validation\n",
    "subset_index_list = [record[1] for record in isl_in_csl_dictionary]\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "def create_path(path):\n",
    "    if not osp.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "num_class = 500\n",
    "color_video_root = \"/home/liweijie/SLR_dataset/S500_color_video\"\n",
    "skeleton_root = \"/home/liweijie/SLR_dataset/xf500_body_color_txt\"\n",
    "val_list = open(\"../input/subset_val_list.txt\",\"w\")\n",
    "\n",
    "color_video_path_list = os.listdir(color_video_root)\n",
    "color_video_path_list.sort()\n",
    "n = len(color_video_path_list)\n",
    "for i,color_video_path in enumerate(color_video_path_list):\n",
    "    print(\"%d/%d\"%(i,n))\n",
    "    label = color_video_path\n",
    "    abs_color_video_path = osp.join(color_video_root,color_video_path)\n",
    "    color_video_list = os.listdir(abs_color_video_path)\n",
    "    color_video_list.sort()\n",
    "    index = int(label)\n",
    "    if index in subset_index_list:\n",
    "        for color_video in color_video_list:\n",
    "            abs_color_video = osp.join(abs_color_video_path,color_video)\n",
    "            if(osp.isdir(abs_color_video)):\n",
    "                p = color_video.split('_')\n",
    "                person = int(p[0].lstrip('P'))\n",
    "                num_frames = len(os.listdir(abs_color_video))\n",
    "                path = osp.join(color_video_path,color_video)\n",
    "                if not '(' in path:\n",
    "                    path_skeleton = path.rstrip(\"color\")+\"body.txt\"\n",
    "                    abs_path_skeleton = osp.join(skeleton_root,path_skeleton)\n",
    "                    if osp.exists(abs_path_skeleton):\n",
    "                        record = path+\"\\t\"+path_skeleton+\"\\t\"+\\\n",
    "                                            str(num_frames)+\"\\t\"+color_video_path+\"\\n\"\n",
    "                        val_list.write(record)\n",
    "                    else:\n",
    "                        print(\"The skeleton path %s don't exist\"%abs_path_skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "f = open('corpus.txt','r')\n",
    "sentences = f.readlines()\n",
    "count = 0\n",
    "csl_dictionary = {}\n",
    "punctuation = [' ','\\n','\\ufeff']\n",
    "for sentence in sentences:\n",
    "    words = jieba.cut(sentence.rstrip('\\n'))\n",
    "    for word in words:\n",
    "        if word not in csl_dictionary.values() and word not in punctuation and '0' not in word:\n",
    "            csl_dictionary[word] = count\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convert_chinese_to_indices() missing 2 required positional arguments: 'dictionary' and 'add_two_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8121b35ccfaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconvert_chinese_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'结果圆满成功﻿'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: convert_chinese_to_indices() missing 2 required positional arguments: 'dictionary' and 'add_two_end'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import time\n",
    "import jieba\n",
    "import json\n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append('..')\n",
    "from utils.textUtils import *\n",
    "convert_chinese_to_indices('结果圆满成功﻿')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isl_dictionary"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit0ecf791bd83b4b4eb3b96ac531fee81e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
