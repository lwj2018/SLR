{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "import jieba\n",
    "import json\n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append('/home/liweijie/projects/SLR')\n",
    "from utils.textUtils import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Record:\n",
    "    def __init__(self,data):\n",
    "        data = data.rstrip('\\n').split()\n",
    "        self.frame_path = data[0]\n",
    "        self.sentence = data[1]\n",
    "\n",
    "\"\"\"\n",
    "Implementation of CSL Phoenix Dataset\n",
    "\"\"\"\n",
    "class CSL_Continuous_Text2Sign(Dataset):\n",
    "    def __init__(self,\n",
    "        setname,\n",
    "        skeleton_root='',\n",
    "        list_file='',\n",
    "        dictionary=None,\n",
    "        upsample_rate=2,\n",
    "        add_two_end=False,\n",
    "        is_normalize=True):\n",
    "        super(CSL_Continuous_Text2Sign,self).__init__()\n",
    "        self.setname = setname\n",
    "        self.skeleton_root = skeleton_root\n",
    "        self.list_file = list_file\n",
    "        self.dictionary = dictionary\n",
    "        self.upsample_rate = upsample_rate\n",
    "        self.add_two_end = add_two_end\n",
    "        self.is_normalize = is_normalize\n",
    "\n",
    "        self.get_data_list()\n",
    "    \n",
    "    def get_data_list(self):\n",
    "        f = open(self.list_file,'r')\n",
    "        self.data_list = []\n",
    "        for data in f.readlines():\n",
    "            record = Record(data)\n",
    "            pind = record.frame_path.find('P')\n",
    "            person = int(record.frame_path[pind+1:pind+3])\n",
    "            label = int(record.frame_path.split('/')[0])\n",
    "            if(person==1):\n",
    "                if self.setname=='train' and label<80:\n",
    "                    self.data_list.append(record)\n",
    "                elif self.setname=='test' and label>=80:\n",
    "                    self.data_list.append(record)\n",
    "\n",
    "    def read_json(self,jsonFile):\n",
    "        skeletonDict = json.load(open(jsonFile,'rb'))\n",
    "        bodySkeleton = numpy.array(skeletonDict['Body']).squeeze()\n",
    "        leftHandSkeleton = numpy.array(skeletonDict['Left hand']).squeeze()\n",
    "        rightHandSkeleton = numpy.array(skeletonDict['Right hand']).squeeze()\n",
    "        mat = numpy.concatenate([bodySkeleton,leftHandSkeleton,rightHandSkeleton],-2)\n",
    "        # 处理误识别出两个骨架的情况\n",
    "        if len(mat.shape)>2:\n",
    "            mat = mat[0]\n",
    "        # 第3维是置信度，不需要\n",
    "        mat = mat[:,:2]\n",
    "        # Normalize\n",
    "        if self.is_normalize:\n",
    "            mat = self.normalize(mat)\n",
    "        mat = torch.Tensor(mat)\n",
    "        return mat\n",
    "\n",
    "    def read_skeletons(self, frame_path, N):\n",
    "        frame_path = os.path.join(self.skeleton_root,frame_path)\n",
    "\n",
    "        skeleton_list = os.listdir(frame_path)\n",
    "        skeleton_list.sort()\n",
    "        # Ignore first frame which is blank\n",
    "        skeleton_list = skeleton_list[1:]\n",
    "        skeletons = []\n",
    "\n",
    "        # Read skeleton data\n",
    "        l = len(skeleton_list)\n",
    "        for i in range(l):\n",
    "            skeleton = self.read_json(os.path.join(frame_path, skeleton_list[i]))\n",
    "            skeletons.append(skeleton)\n",
    "        # After stack, shape is L x J x D\n",
    "        data = torch.stack(skeletons, dim=0)\n",
    "        # Upsample\n",
    "        L,J,D = data.size()\n",
    "        data = data.unsqueeze(0).permute(0,3,1,2)\n",
    "        data = F.upsample(data,size=(self.upsample_rate*L,J),mode='bilinear').contiguous()\n",
    "        data = data.permute(0,2,3,1).squeeze(0)\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data_list[idx]\n",
    "        frame_path = record.frame_path\n",
    "        sentence = convert_chinese_to_indices(record.sentence,self.dictionary,self.add_two_end) \n",
    "        N = len(sentence)\n",
    "        skeletons = self.read_skeletons(frame_path,N)\n",
    "        sentence = torch.LongTensor(sentence)\n",
    "\n",
    "        return {'input':sentence, 'tgt':skeletons}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def normalize(self,mat):\n",
    "        # Shape of mat is: J x D\n",
    "        max_x = numpy.max(mat[:,0])\n",
    "        min_x = min(mat[:,0])\n",
    "        max_y = numpy.max(mat[:,1])\n",
    "        min_y = min(mat[:,1])\n",
    "        center_x = (max_x+min_x)/2\n",
    "        center_y = (max_y+min_y)/2\n",
    "        mat = (mat-[center_x,center_y])/[(max_x-min_x)/2,(max_y-min_y)/2]\n",
    "        # TEST\n",
    "        # print(\"max_x: %.2f,min_x: %.2f,max_y: %.2f,min_y: %.2f\"%(max_x,min_x,max_y,min_y))\n",
    "        return mat\n",
    "\n",
    "def min(array):\n",
    "    threshold = 0.1\n",
    "    min = 999999\n",
    "    for x in array:\n",
    "        if x>threshold and x<min:\n",
    "            min = x\n",
    "    return min\n",
    "\n",
    "# Test\n",
    "if __name__ == '__main__':\n",
    "    # Build dictionary\n",
    "    dictionary = build_dictionary_for_t2s()\n",
    "    # Path settings\n",
    "    skeleton_root = \"/home/haodong/Data/CSL_Continuous_Skeleton\"\n",
    "    train_list = \"/home/liweijie/Data/public_dataset/train_list.txt\"\n",
    "    val_list = \"/home/liweijie/Data/public_dataset/val_list.txt\"\n",
    "    dataset = CSL_Continious_Text2Sign('train',skeleton_root=skeleton_root,list_file=train_list,dictionary=dictionary)\n",
    "    print(len(dataset))\n",
    "    print(dataset[10]['input'].size(),dataset[10]['tgt'].size())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
